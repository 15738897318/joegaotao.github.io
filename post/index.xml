<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Tao Gao | 高涛</title>
    <link>/post/</link>
    <description>Recent content in Posts on Tao Gao | 高涛</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Aug 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>相关、抽样、融合</title>
      <link>/2017/08/28/%E7%9B%B8%E5%85%B3%E6%8A%BD%E6%A0%B7%E8%9E%8D%E5%90%88/</link>
      <pubDate>Mon, 28 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/28/%E7%9B%B8%E5%85%B3%E6%8A%BD%E6%A0%B7%E8%9E%8D%E5%90%88/</guid>
      <description>各个实用的系统工程框架，对于处理一个复杂的目标问题，多半是模块化分级联动的，这类处理方式，在思想上都可以认为有种模型融合（Ensemble）</description>
    </item>
    
    <item>
      <title>博客除草</title>
      <link>/2017/06/11/blog-start/</link>
      <pubDate>Sun, 11 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/11/blog-start/</guid>
      <description>话说三年后又突然给想起博客除草，还是因为这两天不小心溜进了谢老大博客找乐子时，想起他很久就推过的blogdown包，看着如此简单，于是乎啥也</description>
    </item>
    
    <item>
      <title>分布式计算、统计学习与ADMM算法</title>
      <link>/2014/02/11/admm-stat-compute/</link>
      <pubDate>Tue, 11 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/02/11/admm-stat-compute/</guid>
      <description>在整理旧电脑时，才发现13年下半年电脑里有不少残文。老师说，东西搁下了再拿起来花费的时间和之前可能差不多。我一眼看过去这篇关于分布式计算的文</description>
    </item>
    
    <item>
      <title>PKU暑期高维统计学习心得(II)</title>
      <link>/2013/08/10/pku-summer-course2/</link>
      <pubDate>Sat, 10 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/10/pku-summer-course2/</guid>
      <description>前言 距上一篇时间颇长，不过继续Jiashun老师的讲课心得。上一篇谈到稀疏、弱信号的一种处理框架——Higher Criticism，在分类、</description>
    </item>
    
    <item>
      <title>PKU暑期高维统计学习心得(I)</title>
      <link>/2013/07/19/pku-summer-course1/</link>
      <pubDate>Fri, 19 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/19/pku-summer-course1/</guid>
      <description>印象 为其两个周的北大关于高维统计的暑期课程即将告一段落，我回来奔跑了两周，身体略感疲惫，现在总算可以休息下，然后停下来消化下讲过的内容。 这次</description>
    </item>
    
    <item>
      <title>高维变量选择问题的一点总结</title>
      <link>/2013/07/05/high-dim-summary/</link>
      <pubDate>Fri, 05 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/05/high-dim-summary/</guid>
      <description>近十年来，不管是统计界还是计算机界，高维数据问题依然是最热的话题。大数据时代带来的不仅仅是海量的数据，更多的是数据的复杂性和维度的多样性。对</description>
    </item>
    
    <item>
      <title></title>
      <link>/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/</guid>
      <description>印象 为其两个周的北大关于高维统计的暑期课程即将告一段落，我回来奔跑了两周，身体略感疲惫，现在总算可以休息下，然后停下来消化下讲过的内容。
这次来讲课的老师学术能力都很强，都是四大paper等身的青年学者。老师们讲课的风格不一，最好玩的当属Tiefeng Jiang老师，他讲起课来就像说东北二人转，段子一个接一个，东北味的口音让我第一节课毫不犯困。而且深入浅出，随机矩阵这种比较数学的研究领域，也被他讲的比较好理解。不过后面由于有事情，以及之后的内容过于数学化，我就没有再跟下去了。Zhu Ji老师讲的很细致，不过内容偏简单了，听了两节课后我也没有跟下去。Cun-Hui Zhang老师做的很理论，深厚的数理分析功底，以及对高维问题理解的深刻让我感觉很敬畏，不敢靠近。对他后面做的scaled lasso和LPDE的结果很感兴趣，想用来做点检验的试验，不过邮件找老师要代码现在还没有回复，略感伤心，看来只能过几天自己写了。Yang Feng老师很年轻，在Fan老师那边做了很多非常好的工作，不过由于之前我看了不少Fan老师的东西，对他的讲的思路相对比较熟悉，也就没有太用心听而刷微博、做项目去了，真是一大罪过啊！
整个课程中对统计所持的观点和态度，我最欣赏的是Hui Zou和Jiashun Jin老师。
Hui Zou老师在变量选择、图模型做了不少很好的工作，比如现在很常用的elestic net、adaptive lasso等，都是非常简约而好用的工具。Hui Zou老师为人谦虚，对自己所做的东西不夸耀、不吹捧，他认为统计的工作更像是“完成一个产品”的工作，做出来的方法最好能做成软件包为人所用，而且还要比较好用，所以他的文章不少都会附上R包。这一点我很喜欢，统计本身就是一个应用的学科，如果做的过于数理，缺少实际的价值，并且算法写的没效率没法用，这些都是没法促成统计在现实生活大规模应用的。我觉得当前统计之所以这么热，也主要是当年统计从英国转入美国后，有了Tukey等人不断地大力推动数据分析的理念，推进一些有效的统计分析方法，才有了现在统计一片大热的局面和现在所谓大数据的时代。
Zou Hui老师还提倡多做实验，多种方法多做比较，不要限制于一种方法上。我深以为然。以前我学习统计的感觉就是一定要找一个方法完美的解决这个问题，和做数学问题样，做到一个唯一解。后面我逐渐的体悟到，统计面对的是数据，它本身就是具有随机性的，用多种方法来看这个数据虽然结果会有差异，也许某个方法表现比较好，但是不是说明这个方法在后面遇到了同类型的问题时候，在使用这个方法的效果就一定会好。就拿各种penalty的方法，真实数据你也不知道信噪比如何，回归系数是怎么样，也许模拟结果显示某某方法很好，超越了其他方法，但是面对真实数据，好的方法只是“概率性”地增加了我的信心，我无法确定scad一定比lasso分析的好，何况那些oracle性质只是概率意义上的呢，谁知道不会发生小概率事件并且后面Jiashun老师提到的rare/weak signal问题更加增加了我对这些方法的恐慌。所以，做完理论后，回归到数据分析，唯一的办法就是多做比较，大胆假设，小心论证，发现共同的证据，这才是做统计和做数据分析的思维。
整个暑期课程对我思维激发最大的是Jiashun Jin老师的课程内容。由于课程进度有些快，加上这几天比较忙，我也没有研读老师paper，所以此处只是记录些大概想法，后面有时间会深入探讨。
Higher Criticism and Rare/Weak Signals Jiashun老师讲关于稀疏、弱信号（rare/weak signals）共三节课，最核心的是Higher Criticism and rare/weak signals，然后还有就是关于变量选择的新思维。
关于稀疏、弱信号，Jiashun老师认为在大p小n的情况下，有许多没有用的特征，当真实信号非常稀疏和微弱时，参数空间存在着一块不可能对参数进行很好推断的区域。
而导致信号过弱的情况，一个直接原因就是样本过少。信号强度以样本量存在一个2次的比例关系（一般CLT的速度）
(signal strength)^2 ∝ *n* ∝ dollars or manpower
这是一个很浅显的道理，增加样本（如果样本不是高度相关抽样所得），信号肯定会增强，但是很多情况下，随着样本增加，成本会大大提高，或者是维数又会大大增加，信号仍旧比较弱，那么此时如何去恢复或者估计呢？
很多情况下，人们都认为他们的数据中信号是很强的，所以可以直接用那些高维的惩罚方法来恢复信号，或者认为强信号与弱信号之间存在巨大的鸿沟，他们可能没法互相转化，又或者认为信号很弱时，我们什么都不用干，因为什么方法都没用。一般来说，大海里捞针，信号本身确实挺弱的，要想寻找到这样的信号，确实是件非常难的事情。但是我们可以提出一个问题：什么样的情况下我们可以通过一些高维的方法找到这样的弱信号，在什么样的情况下我们又无法很好找到弱信号呢？如何量化这种信号可估和不可估的区域呢？
Jiashun老师从FDR的弱点出发引出了自己的思路。
对于简单的问题
$$Y_i = \mu_i + \sigma z_i, \quad z_i \overset{iid}{\sim} N(0, 1), \quad i = 1, 2, \ldots, p$$
如果只有很少量的信号μi不为0，挑选信号的一个直接的方法就是用Wavelet hard-thresholding，给出一个阈值
$$ \hat{\mu}_i^H = \left \{ \begin{array}{lc} y_i, &amp;amp; |y_i| \geq \sigma \cdot t \</description>
    </item>
    
    <item>
      <title></title>
      <link>/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/</guid>
      <description>前言 距上一篇时间颇长，不过继续Jiashun老师的讲课心得。上一篇谈到稀疏、弱信号的一种处理框架——Higher Criticism，在分类、聚类等领域可以有比较好的应用。具体如何应用，此处不详谈，大家可以看看他第二节课的PPT以及该篇论文。在第二节课结束时，他提了一个结论：
 Surprisingly, penalization methods (e.g., the L0-penalization method) are not optimal for rare/weak signals, even in very simple settings and even with the tuning parameters ideally set。
 也就是说在稀疏、弱信号下，由L0衍生出来的方法并不是最优的，比较容易出问题。虽然我依稀记得某些论文模拟显示信噪比过低时候不少penalty方法结果并不太好，不过Jiashun老师的这个结论还是让我比较吃惊，毕竟被很正经的提出来了，而且他还有相对的解决方案！着实让我很感兴趣。
Donoho的不确定原则（Uncertainty Principle）与信号恢复 Jiashun老师说，关于信号恢复最早应该可以追溯到Donoho在1989年的论文Uncertainty Principle and Signal Recovery。在这片文章中，Donoho给出了类似于海森堡测不准原理的不确定原则（UP）。海森堡测不准原理通俗来讲即微观粒子某些物理量不可能同时被精确测量准确，一个量越确定，另外一个量的不确定程度就越大。Donoho的不确定原则通俗来讲即，离散时间点 *t* = 0, 1, …, *n* − 1 有观测 Yt，做傅里叶变换有
$$ \hat{Y}_w = \frac{1}{\sqrt{n}}\sum^{n-1}_{t=0}Y_t e^{-2\pi it/n}, \quad w = 0, 1, \ldots, n - 1 $$
用 T 和 W 分别表示 Yt 和 $\hat{Y}_w$ 中的非零的位置，那么就会得到一个不确定原则，</description>
    </item>
    
    <item>
      <title></title>
      <link>/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/</guid>
      <description>在整理旧电脑时，才发现13年下半年电脑里有不少残文。老师说，东西搁下了再拿起来花费的时间和之前可能差不多。我一眼看过去这篇关于分布式计算的文章，貌似还真的没有了当时理解的深度和感觉。当时还想利用ADMM算法，把统计中常见的带惩罚的高维问题在此框架下用R重写一下，但是中途多种事情一耽搁，就早已抛之脑后。看来任何事情，真的还是需要坚持，哪怕拨点时间都是好的。先把一篇残文扔出来祭奠下过去的13年吧。公式多文字长，慎入！
业界一直在谈论大数据，对于统计而言，大数据其实意味着要不是样本量增加*n* → ∞，要不就是维度的增加*p* → ∞，亦或者两者同时增加，并且维度与样本量的增长速度呈线性或者指数型增长。在稀疏性的假设条件下，再加上一些正则性方法，统计学家可以证明各种加penalty的模型所给出的参数估计具有良好的统计性质，收敛速度也有保证，同时还会给出一些比较好的迭代算法，但是，他们并没有考虑真实环境下的所消耗的计算时间。虽然统计学家也希望尽量寻求迭代数目比较少的算法（比如one-step估计），但是面对真实的Gb级别以上的数据，很多时候我们还是无法直接用这些算法，原因是一般的硬件都无法支撑直接对所有数据进行运算的要求。如果想减少抽样误差，不想抽样，又想提高估计的精度，那么还是需要寻求其他思路，结合已有的模型思想来解决这些问题。在目前条件下，并行化、分布式计算是一种比较好的解决思路，利用多核和多机器的优势，这些好算法便可以大规模应用，处理大数据优势便体现出来了。对于统计而言，数据量越大当然信息越可能充分（假设冗余成分不是特别多），因为大样本性质本身就希望样本越多越好嘛。
本文是基于Stephen Boyd 2011年的文章《Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers》进行的翻译和总结。Boyd也给出了利用matlab的CVX包实现的多种优化问题的matlab示例。
 优化的一些基本算法思想 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-  ADMM算法并不是一个很新的算法，他只是整合许多不少经典优化思路，然后结合现代统计学习所遇到的问题，提出了一个比较一般的比较好实施的分布式计算框架。因此必须先要了解一些基本算法思想。
1.1 Dual Ascent 对于凸函数的优化问题，对偶上升法核心思想就是引入一个对偶变量，然后利用交替优化的思路，使得两者同时达到optimal。一个凸函数的对偶函数其实就是原凸函数的一个下界，因此可以证明一个较好的性质：在强对偶性假设下，即最小化原凸函数（primal）等价于最大化对偶函数（dual），两者会同时达到optimal。这种转化可以将原来很多的参数约束条件变得少了很多，以利于做优化。具体表述如下：
$$ \begin{array}{lc} \min &amp;amp; f(x)\
s.t. &amp;amp; Ax = b \
\end{array} \Longrightarrow L(x, y) = f(x) + y^T(Ax - b) \overset{对偶函数（下界）}{\Longrightarrow} g(y) = \inf_x L(x, y) $$
在强对偶性的假设下，primal和dual问题同时达到最优。
x⋆ = argminxL(x, y⋆)
因此，若对偶函数g(y)可导，便可以利用梯度上升法，交替更新参数，使得同时收敛到最优。迭代如下：
$$ \begin{split} x^{k + 1} : &amp;amp; =\arg\min_x L(x, y^k) \quad \text{($x$-最小化步)} \</description>
    </item>
    
    <item>
      <title></title>
      <link>/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/</guid>
      <description>各个实用的系统工程框架，对于处理一个复杂的目标问题，多半是模块化分级联动的，这类处理方式，在思想上都可以认为有种模型融合（Ensemble）味道。比如实操中，我们多会大任务化解为小任务，难目标分解为多个较为易解的目标，最终的问题则成为了多小问题后的组合和综合。相比一上来想要用一套模型来解决，这种处理方式也更加接近实际工作方式。因为任务一旦较好的拆解，就可以分配给多个人来并行处理，相比集中式的在某个模型上解决一个难问题可能有效得多。
所以换个角度来看统计学，深度学习中框架性的设计我觉得是传统统计最应该学习的地方，好的框架不仅仅对于解决问题非常有帮助，并且也好理解好调试。虽然一个问题被分级分块处理，可能没法做到深度学习用一个后向传播算法来统一调整，也不如单模型简洁优美，但是实际用起来更好用，更能有效解决问题。所以在软件工程上，有系统架构师掌舵，在数据建模上，应该也有数据模型架构师掌舵，设计的框架耦合性不高，在框架的每个角落，你都可以尽情尝试和打磨各类方法，进而推动整个结果的进化。下面我们就来谈谈关于模型融合的一些有用的东西。
1. 一个重要而实用的定理 对于模型融合（Ensemble）思想，抽样和相关性处在比较重要的理论和实践地位，并且两者紧密结合。相关性和抽样对于模型融合的影响，可以用经典的偏误差分解方法来探究，这样可以让我们更深刻的理解每块设计所带来的影响，进而在自己设计整个ensemble框架时，知道哪些是更重要值得花精力的点，哪些相对次要。
在关于模型选择的讨论中，我们知道对于平方损失，某个点的预测误差，可以分解为如下三部分
$$ \begin{split} \text{Err}(x_0) &amp;amp; = \mathbb{E}(L(y_0, \hat{f}(x_0))| X = x_0) \
&amp;amp; = \underbrace{\sigma^2_{\epsilon}}_{IrreducibleError} + \underbrace{(f(x_0) - \mathbb{E}\hat{f}(x_0)) ^ 2}_{ModelBias^2} + \underbrace{\mathbb{E}(\hat{f}(x_0) - \mathbb{E}\hat{f}(x_0))^2}_{ModelVariance} \end{split} $$
对于基于样本和特征抽样随机模型，也可推导出如上的分解式子，令*δ*表示控制模型随机性的参数（随机性可以体现在对样本的随机抽取上，也可以体现在对于特征的随机抽取上），𝒯为训练集，那么融合起来一系列随机模型的平均值$\Psi_{\mathcal{T}, \delta_{1,..m}}(\mathbf{x}) = \frac{1}{M}\sum^M_{m=1} \hat{f}_{\mathcal{T}, \delta_m}(\mathbf{x})$的期望平均损失为
𝔼𝒯(Err(Ψ𝒯, δ1, ..m(x)))=noise(x)+bias2(x)+variance(x) 其中
$$ \left\{ \begin{array}{l} \text{noise}(\mathbf{x}) = \sigma^2_{\epsilon}\
\text{bias}^2(\mathbf{x}) = (f(\mathbf{x}) - u_{\mathcal{T}, \delta}(\mathbf{x}))^2, \,\,\, u_{\mathcal{L}, \delta}(\mathbf{x}) = \mathbb{E}_{\mathcal{T},\delta}(\hat{f}_{\mathcal{T}, \delta}(\mathbf{x}))\
\text{variance}(\mathbf{x}) = \rho(\mathbf{x}) \sigma^2_{\mathcal{T}, \delta}(\mathbf{x}) + \frac{1 - \rho(\mathbf{x})}{M} \sigma^2_{\mathcal{T}, \delta}(\mathbf{x}), \,\,\, \sigma^2_{\mathcal{T}, \delta}(\mathbf{x})=\mathbb{Var}_{\mathcal{T},\delta}(\hat{f}_{\mathcal{T},\delta}(\mathbf{x})) \end{array} \right.</description>
    </item>
    
  </channel>
</rss>